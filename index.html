<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Deformable Neural Radiance Fields creates free-viewpoint portraits (nerfies) from casually captured videos.">
  <meta name="keywords" content="LLM, Instruction Tuning, Sequential Instructions">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>SIT: Fine-Tuning Large Language Models with Sequential Instructions</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/chains_icon.png">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">
            <!-- <img src="static/images/chains_icon.png" alt="Icon" style="vertical-align: middle; height: 1em; margin-right: 0.0em;"> -->
            Fine-Tuning Large Language Models with Sequential Instructions
          </h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://openreview.net/profile?id=~Hanxu_Hu1">Hanxu Hu*</a><sup>‚Ä†,1</sup>,</span>
            <span class="author-block">
              <a href="https://simon-yu.netlify.app/">Simon Yu*</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="https://pinzhenchen.github.io/">Pinzhen Chen*</a><sup>1</sup>,
            </span>
            <span class="author-block">
              <a href="https://ducdauge.github.io/">Edoardo M. Ponti</a><sup>‚Ä†,1</sup>,
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>School of Informatics, University of Edinburgh</span>
          </div>
          <div class="is-size-5 publication-authors">
            <span class="author-block">*Equal contribution</span>
          </div>
          <div class="is-size-5 publication-authors">
            <span class="author-block">‚Ä†Corresponding author: <a href="mailto:hanxu.hu@ed.ac.uk">hanxu.hu@ed.ac.uk</a>,<a href="mailto:eponti@ed.ac.uk">eponti@ed.ac.uk</a></span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://arxiv.org/abs/2403.07794"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/hanxuhu/SeqIns"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              <!-- HF dataset Link. -->
              <span class="link-block">
                <a href="https://huggingface.co/collections/HanxuHU/sequential-instruction-datasets-667687a3aacacf620e3cf857"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      ü§ó
                  </span>
                  <span>HF Dataset</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://huggingface.co/collections/HanxuHU/seqinst-models-667536ee1192e834e9ae02d2"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      ü§ó
                  </span>
                  <span>HF Space</span>
                </a>
              </span>
              </span>
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <style>
      .quote-container {
          border: 2px dashed #d3d3d3;
          border-radius: 10px;
          padding: 20px;
          width: fit-content;
          margin: 20px auto;
          font-family: Arial, sans-serif;
          color: #2f4f4f;
      }
      .quote {
          font-style: italic;
          color: #5f9ea0;
      }
      .author {
          text-align: right;
          margin-top: 10px;
          font-weight: bold;
      }
  </style>
  <title>Quote Box</title>
</head>

<head>
  <style>
    .hero.teaser.custom-teaser .container.custom-container .hero-body.custom-hero-body {
      overflow: visible !important; /* Ensure the overflow is visible */
      position: relative;
    }

    .hero.teaser.custom-teaser .container.custom-container .hero-body.custom-hero-body img.custom-size-image {
      width: 200% !important; /* Increase the width significantly */
      margin-left: -50% !important; /* Adjust the margin to extend outside the container */
      display: block;
    }

    .hero.teaser.custom-teaser {
      overflow: visible !important; /* Ensure the section allows overflow */
    }

    .container.custom-container {
      overflow: visible !important; /* Ensure the container allows overflow */
    }
  </style>
</head>

<div class="quote-container">
  <p class="quote">"Finish the paper, release the code and data, and then tweet about this paper"</p>
  <p class="author">‚Äî- Can language model handle this kind of sequential instructions well?</p>
</div>

<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Introduction</h2>
        <div class="content has-text-justified">
          Despite the success of existing instruction-tuned models, we find that they usually struggle to follow sequential instructions  to queries with <b>multiple instructions</b>. This impairs their
          performance in complex problems whose solution consists of multiple intermediate tasks. 
          Therefore, we contend that part of the fine-tuning data mixture should be
          sequential‚Äîcontaining a chain of interrelated tasks. We first approach sequential
          instruction tuning from a task-driven perspective, manually creating multilingual and multimodal tasks: namely ‚Äútranslate then predict‚Äù and ‚Äúcaption then answer‚Äù. 
          Next, we further push the boundary by turning instructions in existing datasets (e.g., Alpaca, FlanCoT and Tulu) into diverse
          and complex sequential instructions, making our method general-purpose. Models
          that underwent our sequential instruction tuning show improved results in reasoning and open-ended generation. 
          Moreover, we put forward a new benchmark named <b>SeqEval</b> to evaluate a model's ability to follow all the instructions in a
          sequence, which further corroborates the benefits of our fine-tuning method.
        </div>
      </div>
    </div>
    <!--/ Abstract. -->
</section>


<section class="hero teaser custom-teaser">
  <div class="container custom-container">
    <div class="hero-body custom-hero-body">
      <h2 class="subtitle has-text-centered">
        <span class="dnerf">SeqIT</span> trained on dataset augmented with sequential instructions, enhancing both generic tasks and sequential tasks compared to standard Instruction Tuning methods.
      </h2>
      <img src="static/images/mainfig_nips24.jpg" alt="SeqIT" style="width: 200% !important; margin-left: -50% !important;" />
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Overview</h2>
        <div class="content has-text-justified">
          <p><b>The issue: Instruction-tuned models perform poorly in sequential tasks</b><br>Despite models showed remarkable capabilities on single instructions, we find that they usually struggle to respond to queries with multiple instructions. 
            This impairs their performance in complex problems whose solution consists of multiple intermediate tasks.
          <p><b>Why is it the case and what does it mean "Sequential Instruction"? </b><br>The main reason is most instruction data are consist single query (Alpaca) or generate from NLP tasks (FlanCoT). 
            We contend that part of the fine-tuning data mixture should be sequential---containing a chain of interrelated tasks. 
            Some of these examples are intermediate tasks for <b>multilingual</b> and <b>VQA</b>: namely "translate then predict" and "caption then answer".
          <p><b>What is <b>SIT</b>?</b><br>
            We propose <b>Sequential Instruction Tuning (SIT)</b>, a novel fine-tuning method that leverages sequential instructions to enhance the performance of large language models (LLMs) on both generic tasks and sequential tasks.
            <p><b>How good is <b>SIT</b>?</b><br>
            Experiments show that <b>SIT significantly outperforms vanilla IT and WizardLM on both generic tasks and sequential tasks</b>. 
            Specifically, SIT show superior results on reasoning and coding tasks (GSM8K, Codex HumanEval), XQuAD and MGSM (multilingual translation), and it shows significant improvement on SeqEval (evolved from AlpacaEval).
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->
</section>

<!-- Main Results and Analysis -->
<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Results and Analysis</h2>
        <div class="columns is-vcentered interpolation-panel">
        </div>
        <br/>
        <div class="content has-text-justified">
          <h3 class="title is-4">Main Results</h3>
          <p>
          <span style="color: red"><b>SIT</b></span> outperforms vanilla IT or WizardLM (response regenerated using the same models) across generic tasks, such as reasoning and coding task. And outperforming in sequential tasks by a large margin. 
          </p>
          <img src="static/images/main-general.jpg" alt="results">
        </div>
        <div class="content has-text-justified">
          <h3 class="title is-4">Analysis</h3>
          <style>
            .image-container {
              display: flex;
              gap: 10px; /* Adds space between the images */
            }
          
            .image-container img {
              max-width: 85%; /* Ensures images are responsive */
              height: auto;
            }
          </style>
          
          <div class="image-container">
            <img src="static/images/ablation.jpg" alt="analysis results">
            <img src="static/images/root_verb.jpg" alt="Root verb distribution">
          </div>
          <h4 class="title is-8">(A) Ablations</h4>
          <p>Our ablation results show that our method are agnostic to the choice of both base model and generation models. For both G=</p>

          <h4 class="title is-8">(B) Is Sequence Length the Driving Factor Behind Performance? </h4> 
          <p>A variable factor in our comparison of IT and SIT is the length of the training data, based on this, we
            prepare three ablation experiments to investigate whether SIT‚Äôs higher metric scores are attributed to
            merely having more training tokens.</p>
          <h4 class="title is-8">(C) Root Verb anylaze in new instructions</h4>
          <p>we check the kinds of instructions generated via Seq-Instruct and draw potential links to
            model improvements in different skill types. We identify the verb-noun structure in the generated
            instructions using the Berkeley Neural Parser. </p>
        </div>
      </section>


<section class="section" id="BibTeX">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
        <h2 class="title is-3">BibTeX</h2>
        <pre><code>@article{Hu2024FinetuningLL,
          title={SIT: Fine-tuning Large Language Models with Sequential Instructions},
          author={Hanxu Hu and Simon Yu and Pinzhen Chen and Edoardo Maria Ponti},
          journal={ArXiv},
          year={2024},
          volume={abs/2403.07794}
        }</code></pre>
      </div>
  </div>
</section>


<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <a class="icon-link"
         href="./static/videos/nerfies_paper.pdf">
        <i class="fas fa-file-pdf"></i>
      </a>
      <a class="icon-link" href="https://github.com/keunhong" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a>
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is website adapted from <a
              href="https://github.com/nerfies/nerfies.github.io">Nerfies</a>. This website is licensed under a <a rel="license"
              href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
