<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Deformable Neural Radiance Fields creates free-viewpoint portraits (nerfies) from casually captured videos.">
  <meta name="keywords" content="LLM, Instruction Tuning, Sequential Instructions">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>SIT: Fine-Tuning Large Language Models with Sequential Instructions</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/chains_icon.png">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">
            <!-- <img src="static/images/chains_icon.png" alt="Icon" style="vertical-align: middle; height: 1em; margin-right: 0.0em;"> -->
            SIT: Fine-Tuning Large Language Models with Sequential Instructions
          </h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://openreview.net/profile?id=~Hanxu_Hu1">Hanxu Hu*</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="https://simon-yu.netlify.app/">Simon Yu*</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="https://pinzhenchen.github.io/">Pinzhen Chen*</a><sup>1</sup>,
            </span>
            <span class="author-block">
              <a href="https://ducdauge.github.io/">Edoardo M. Ponti</a><sup>1</sup>,
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>School of Informatics, University of Edinburgh</span>
          </div>
          <div class="is-size-5 publication-authors">
            <span class="author-block">*Equal contribution</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://arxiv.org/abs/2403.07794"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/hanxuhu/SeqIns"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              <!-- HF dataset Link. -->
              <span class="link-block">
                <a href="https://huggingface.co/EdinburghNLP/SeqIns"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      ðŸ¤—
                  </span>
                  <span>HF Dataset</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://huggingface.co/collections/HanxuHU/seqinst-models-667536ee1192e834e9ae02d2"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      ðŸ¤—
                  </span>
                  <span>HF Space</span>
                </a>
              </span>
              </span>
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

</section>
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <h2 class="subtitle has-text-centered">
        <span class="dnerf">SeqIT</span> learns to retrieve, generate and critique to enhance LM's output quality and factuality, enhancing both generic tasks and sequential tasks compared to Instruction Tuning and WizardLM.
      </h2>
      <img src="static/images/mainfig_nips24.jpg" alt="SeqIT" />
    </div>
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Summary</h2>
        <div class="content has-text-justified">
          <p><b>The issue: Instruction-tuned models perform poorly in sequential tasks</b><br>Despite models showed remarkable capabilities on single instructions, we find that they usually struggle to respond to queries with multiple instructions. 
            This impairs their performance in complex problems whose solution consists of multiple intermediate tasks.
          <p><b>Why is it the case and what does it mean "Sequential Instruction"? </b><br>The main reason is most instruction data are consist single query (Alpaca) or generate from NLP tasks (FlanCoT). 
            We contend that part of the fine-tuning data mixture should be sequential---containing a chain of interrelated tasks. 
            Some of these examples are intermediate tasks for <b>multilingual</b> and <b>VQA</b>: namely "translate then predict" and "caption then answer".
          <p><b>What is <b>SIT</b>?</b><br>
            We propose <b>Sequential Instruction Tuning (SIT)</b>, a novel fine-tuning method that leverages sequential instructions to enhance the performance of large language models (LLMs) on both generic tasks and sequential tasks.
            <p><b>How good is <b>SIT</b>?</b><br>
            Experiments show that <b>SIT significantly outperforms vanilla IT and WizardLM on both generic tasks and sequential tasks</b>. 
            Specifically, SIT show superior results on reasoning and coding tasks (GSM8K, Codex HumanEval), XQuAD and MGSM (multilingual translation), and it shows significant improvement on SeqEval (evolved from AlpacaEval).
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->
</section>

<!-- Main Results and Analysis -->
<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Results and Analysis</h2>
        <div class="columns is-vcentered interpolation-panel">
        </div>
        <br/>
        <div class="content has-text-justified">
          <h3 class="title is-4">Main Results</h3>
          <p>
          <span style="color: red"><b>SIT</b></span> outperforms vanilla IT or WizardLM (response regenerated using the same models) across generic tasks, such as reasoning and coding task. And outperforming in sequential tasks by a large margin. 
          </p>
          <img src="static/images/main-general.jpg" alt="results">
        </div>
        <div class="content has-text-justified">
          <h3 class="title is-4">Analysis</h3>
          <style>
            .image-container {
              display: flex;
              gap: 10px; /* Adds space between the images */
            }
          
            .image-container img {
              max-width: 85%; /* Ensures images are responsive */
              height: auto;
            }
          </style>
          
          <div class="image-container">
            <img src="static/images/ablation.jpg" alt="analysis results">
            <img src="static/images/root_verb.jpg" alt="Root verb distribution">
          </div>
          <h4 class="title is-8">(A) Ablations</h4>
          <p>Our ablation results show that our method are agnostic to the choice of both base model and generation models. For both G=</p>

          <h4 class="title is-8">(B) Is Sequence Length the Driving Factor Behind Performance? </h4> 
          <p>Self-RAG enables practitioners to tailor model's behaviors for different fine-grained preferences. For instance, putting more emphasis on whether a model generation is supported by the evidence can increase citation precision (precision in Figure (b)) on long-form generation, while putting less emphasis on it can increase the output fluency as a model may generate output more flexibly and fluently, regardless of whether it is supported by the cite evidence.</p>
          <h4 class="title is-8">(C) Root Verb anylaze in new instructions</h4>
          <p>Self-RAGgenerates retrieval tokens by itself when it judges retrieval is necessary, while one can also increase or decrease retrieval frequency based on diverse end tasks. As you can see, retrieval less can hurt performance on Open domain QA (PopQA; 40% relative performance drop) while it gives marginal performance deterioration in fact verification task (PubHealth; 2%).</p>
        </div>
      </section>



<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@article{Hu2024FinetuningLL,
      title={SIT: Fine-tuning Large Language Models with Sequential Instructions},
      author={Hanxu Hu and Simon Yu and Pinzhen Chen and Edoardo Maria Ponti},
      journal={ArXiv},
      year={2024},
      volume={abs/2403.07794}
    }</code></pre>
  </div>
</section>


<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <a class="icon-link"
         href="./static/videos/nerfies_paper.pdf">
        <i class="fas fa-file-pdf"></i>
      </a>
      <a class="icon-link" href="https://github.com/keunhong" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a>
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is website adapted from <a
              href="https://github.com/nerfies/nerfies.github.io">Nerfies</a>. This website is licensed under a <a rel="license"
              href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
